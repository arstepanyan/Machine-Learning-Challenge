{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "1. http://docs.h2o.ai/h2o/latest-stable/h2o-docs/starting-h2o.html\n",
    "2. https://github.com/h2oai/h2o-tutorials/blob/master/tutorials/gbm-randomforest/GBM_RandomForest_Example.py\n",
    "3. https://blog.h2o.ai/2017/06/xgboost-in-h2o-machine-learning-platform/\n",
    "4. https://www.analyticsvidhya.com/blog/2016/05/h2o-data-table-build-models-large-data-sets/\n",
    "5. https://aichamp.wordpress.com/2017/10/19/calculating-auc-and-gini-model-metrics-for-logistic-classification/\n",
    "6. Parameter tuning: https://github.com/h2oai/h2o-3/blob/master/h2o-docs/src/product/tutorials/gbm/gbmTuning.ipynb\n",
    "7. Interpreting h2o predictions: https://stackoverflow.com/questions/45523997/how-should-we-interpret-the-results-of-the-h2o-predict-function\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Shape: (348978, 51) test Shape: (523466, 50)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# this will take sevaral seconds\n",
    "train = pd.read_csv('data_transactions/train.csv')\n",
    "test = pd.read_csv('data_transactions/test.csv')\n",
    "\n",
    "print('train Shape:', train.shape, 'test Shape:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop id column\n",
    "train_new = train.copy()\n",
    "test_new = test.copy()\n",
    "\n",
    "id_train = train_new.transaction_id\n",
    "sub_ids = test_new.transaction_id\n",
    "\n",
    "train_new.drop('transaction_id', axis = 1, inplace = True)\n",
    "test_new.drop('transaction_id', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Features With Only One Distinct Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(348978, 42)\n",
      "(523466, 41)\n"
     ]
    }
   ],
   "source": [
    "cat_vars = [x for x in train_new.columns if 'cat_' in x]\n",
    "\n",
    "# in training set\n",
    "cat_to_drop_train = []\n",
    "for x in cat_vars:\n",
    "    if train_new[x].nunique() == 1:\n",
    "        cat_to_drop_train.append(x)\n",
    "\n",
    "# in test set\n",
    "cat_to_drop_test = []\n",
    "for x in cat_vars:\n",
    "    if test_new[x].nunique() == 1:\n",
    "        cat_to_drop_test.append(x)\n",
    "\n",
    "# drop these features\n",
    "cat_to_drop = list(set(cat_to_drop_train + cat_to_drop_test))\n",
    "train_new = train_new.drop(cat_to_drop, axis = 1)\n",
    "test_new = test_new.drop(cat_to_drop, axis = 1)\n",
    "\n",
    "print(train_new.shape)\n",
    "print(test_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(348978, 42)\n",
      "(523466, 41)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "cat_vars = [x for x in train_new.columns if 'cat_' in x]\n",
    "\n",
    "for x in cat_vars:\n",
    "    train_new[x] = train_new[x].fillna('NaN')\n",
    "    test_new[x] = test_new[x].fillna('NaN')\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(list(set(list(train_new[x]) + list(test_new[x]))))\n",
    "    train_new[x] = encoder.transform(train_new[x])\n",
    "    test_new[x] = encoder.transform(test_new[x])\n",
    "    \n",
    "print(train_new.shape)\n",
    "print(test_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting H20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>14 hours 8 mins</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.16.0.2</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>7 days, 16 hours and 14 minutes </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_araks_byqnlx</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>1001 Mb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.5.4 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O cluster uptime:         14 hours 8 mins\n",
       "H2O cluster version:        3.16.0.2\n",
       "H2O cluster version age:    7 days, 16 hours and 14 minutes\n",
       "H2O cluster name:           H2O_from_python_araks_byqnlx\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    1001 Mb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  4\n",
       "H2O cluster status:         locked, healthy\n",
       "H2O connection url:         http://localhost:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.5.4 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "import os\n",
    "h2o.init()     #h2o.cluster().shutdown() # in the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "train_h2o = h2o.H2OFrame(train_new)\n",
    "test_h2o = h2o.H2OFrame(test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run this sell when importing the data from the files directly\n",
    "\n",
    "#train_h2o = h2o.import_file(os.path.realpath(\"data_transactions/train.csv\"))\n",
    "#test_h2o = h2o.import_file(os.path.realpath(\"data_transactions/test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns to factors (don't do this step if the data were encoded before h2o)\n",
    "#cat_vars = [x for x in train_h2o.col_names if 'cat_' in x]\n",
    "\n",
    "#for column in cat_vars:\n",
    "#    train_h2o[column] = train_h2o[column].asfactor()\n",
    "    \n",
    "train_h2o['target'] = train_h2o['target'].asfactor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_h2o.col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "from h2o.estimators.random_forest import H2ORandomForestEstimator\n",
    "#help(H2OGradientBoostingEstimator)\n",
    "#help(h2o.import_file)\n",
    "\n",
    "# Prepare Predictors and Response\n",
    "predictors_X = train_h2o.col_names[:-1]     #last column is our desired response variable \n",
    "response_y_train = train_h2o.col_names[-1] \n",
    "\n",
    "# Split the data\n",
    "train, valid, test = train_h2o.split_frame(ratios = [0.8, 0.1], seed = 1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "rf_v1 = H2ORandomForestEstimator(\n",
    "    model_id=\"rf_v1\",\n",
    "    ntrees=200,\n",
    "    stopping_rounds=2,\n",
    "    score_each_iteration=True,\n",
    "    seed=1000000)\n",
    "\n",
    "rf_v1.train(predictors_X, response_y_train, training_frame = train, validation_frame = valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score 0.720998398637594\n",
      "validation score 0.7215307122598251\n"
     ]
    }
   ],
   "source": [
    "print('training score', rf_v1.auc(train = True))\n",
    "print('validation score', rf_v1.auc(valid = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7210501376552523"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we can see the hit ratio table.\n",
    "#rf_v1.hit_ratio_table(valid = True)\n",
    "\n",
    "rf_v1_perf = rf_v1.model_performance(test)\n",
    "auc_rf_v1 = rf_v1_perf.auc()\n",
    "auc_rf_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBM 1\n",
    "\n",
    "Default parameters. As the scores show below, this gbm with defailt parameters is worse than previous random forest. Is it overfitting?\n",
    "\n",
    "1. Default number of trees - 50\n",
    "2. Default learning rate - 0.1\n",
    "3. Default depth - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# First we will use all default settings, then make some changes to improve our predictions.\n",
    "\n",
    "gbm_v1 = H2OGradientBoostingEstimator(\n",
    "    model_id=\"gbm_covType_v1\",\n",
    "    seed=2000000\n",
    ")\n",
    "\n",
    "gbm_v1.train(predictors_X, response_y_train, training_frame = train, validation_frame = valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score 0.7252709618760613\n",
      "validation score 0.7143121713614224\n"
     ]
    }
   ],
   "source": [
    "print('training score', gbm_v1.auc(train = True))\n",
    "print('validation score', gbm_v1.auc(valid = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7185211253312612"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gbm_v1.score_history()\n",
    "#gbm_v1.hit_ratio_table(valid=True)\n",
    "gbm_v1_perf = gbm_v1.model_performance(test)\n",
    "auc_gbm_v1 = gbm_v1_perf.auc()\n",
    "auc_gbm_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  GBM 2\n",
    "\n",
    "2. increase the learning rate (from default 0.1 to 0.2)\n",
    "3. increase the depth (from default 5 to 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "gbm_v2 = H2OGradientBoostingEstimator(\n",
    "    ntrees=50,\n",
    "    learn_rate=0.2,\n",
    "    max_depth=10,\n",
    "    #stopping_tolerance=0.01, #10-fold increase in threshold as defined in rf_v1\n",
    "    #stopping_rounds=2,\n",
    "    score_each_iteration=True,\n",
    "    model_id=\"gbm_covType_v2\",\n",
    "    seed=2000000\n",
    ")\n",
    "\n",
    "gbm_v2.train(predictors_X, response_y_train, training_frame = train, validation_frame = valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score 0.7544961982216296\n",
      "validation score 0.7203838970531827\n"
     ]
    }
   ],
   "source": [
    "print('training score', gbm_v2.auc(train = True))\n",
    "print('validation score', gbm_v2.auc(valid = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the scores above, we clearly see that we started overfitting the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.722512760954005"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gbm_v2.score_history()\n",
    "gbm_v2_perf = gbm_v2.model_performance(test)\n",
    "auc_gbm_v2 = gbm_v2_perf.auc()\n",
    "auc_gbm_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we are improving the results, but I am a little concerned about overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBM 3\n",
    "\n",
    "1. Increase learning rate (to 0.3)\n",
    "2. Use a random 70% of rows to fit each tree (to add the nature of randomness). This will help prevent overfitting\n",
    "3. Use a random 70% of columns to fit each tree (to add the nature of randomness). Will help prevent overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "gbm_v3 = H2OGradientBoostingEstimator(\n",
    "    ntrees=50,\n",
    "    learn_rate=0.3,\n",
    "    max_depth=10,\n",
    "    sample_rate=0.7,\n",
    "    col_sample_rate=0.7,\n",
    "    #stopping_rounds=2,\n",
    "    #stopping_tolerance=0.01, #10-fold increase in threshold as defined in rf_v1\n",
    "    score_each_iteration=True,\n",
    "    model_id=\"gbm_covType_v3\",\n",
    "    seed=2000000\n",
    ")\n",
    "gbm_v3.train(predictors_X, response_y_train, training_frame=train, validation_frame=valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score 0.7677209218922407\n",
      "validation score 0.7167701304997257\n"
     ]
    }
   ],
   "source": [
    "print('training score', gbm_v3.auc(train = True))\n",
    "print('validation score', gbm_v3.auc(valid = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7214806279781103"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_v3_perf = gbm_v3.model_performance(test)\n",
    "auc_gbm_v3 = gbm_v3_perf.auc()\n",
    "auc_gbm_v3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBM 4\n",
    "\n",
    "Adding random nature doesn't seem to help overfitting. But we also increased the learning rate on the previous model. So let's bring the learning rate back to 0.2 as in the gbm2 and increase the number of trees.\n",
    "\n",
    "1. Decrease learning rate (from 0.3 to 0.2)\n",
    "2. Increase number of trees (from 50 to 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "gbm_v4 = H2OGradientBoostingEstimator(\n",
    "    ntrees=70,\n",
    "    learn_rate=0.2,\n",
    "    max_depth=10,\n",
    "    sample_rate=0.7,\n",
    "    col_sample_rate=0.7,\n",
    "    #stopping_rounds=2,\n",
    "    #stopping_tolerance=0.01, #10-fold increase in threshold as defined in rf_v1\n",
    "    score_each_iteration=True,\n",
    "    model_id=\"gbm_covType_v3\",\n",
    "    seed=2000000\n",
    ")\n",
    "gbm_v4.train(predictors_X, response_y_train, training_frame=train, validation_frame=valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score 0.7643044136441797\n",
      "validation score 0.7201199168954743\n"
     ]
    }
   ],
   "source": [
    "print('training score', gbm_v4.auc(train = True))\n",
    "print('validation score', gbm_v4.auc(valid = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7195996493722369"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_v4_perf = gbm_v4.model_performance(test)\n",
    "auc_gbm_v4 = gbm_v4_perf.auc()\n",
    "auc_gbm_v4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest 2\n",
    "\n",
    "As the first random forest's result are very comparable to the gbm models' results, let's tune the parameters a little and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# takes more than 5 minutes without the stopping conditions\n",
    "\n",
    "rf_v2 = H2ORandomForestEstimator(\n",
    "    model_id=\"rf_covType_v2\",\n",
    "    ntrees=200,\n",
    "    max_depth=30,\n",
    "    stopping_rounds=2,    \n",
    "    stopping_tolerance=0.01,\n",
    "    score_each_iteration=True,\n",
    "    seed=3000000)\n",
    "\n",
    "rf_v2.train(predictors_X, response_y_train, training_frame=train, validation_frame=valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score 0.7199379695749945\n",
      "validation score 0.7189576972585479\n"
     ]
    }
   ],
   "source": [
    "print('training score', rf_v2.auc(train = True))\n",
    "print('validation score', rf_v2.auc(valid = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7258007575388039"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_v2_perf = rf_v2.model_performance(test)\n",
    "auc_rf_v2 = rf_v2_perf.auc()\n",
    "auc_rf_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not so sure, maybe the gbm2 is the best after all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And the winner model is GBM 2 (temporarely, until tuning parameters more)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# fit on the whole training set\n",
    "gbm_v2.train(predictors_X, response_y_train, training_frame=train_h2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Convert columns to factorsin test data (don't do this step if the data were encoded before h2o)\n",
    "#cat_vars = [x for x in test_h2o.col_names if 'cat_' in x]\n",
    "\n",
    "#for column in cat_vars:\n",
    "#    test_h2o[column] = test_h2o[column].asfactor()\n",
    "\n",
    "# Make predictions\n",
    "final_gbm_predictions = gbm_v2.predict(test_h2o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand h2o predictions and convert to pandas data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(523466, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">      p0</th><th style=\"text-align: right;\">       p1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.937585</td><td style=\"text-align: right;\">0.0624148</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.935907</td><td style=\"text-align: right;\">0.064093 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.936524</td><td style=\"text-align: right;\">0.063476 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.93463 </td><td style=\"text-align: right;\">0.0653702</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.938609</td><td style=\"text-align: right;\">0.061391 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.940626</td><td style=\"text-align: right;\">0.0593745</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.912474</td><td style=\"text-align: right;\">0.0875262</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.921667</td><td style=\"text-align: right;\">0.0783328</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.949965</td><td style=\"text-align: right;\">0.0500351</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.939633</td><td style=\"text-align: right;\">0.0603669</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method H2OFrame.type of >\n"
     ]
    }
   ],
   "source": [
    "print(final_gbm_predictions.shape)\n",
    "print(final_gbm_predictions.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "Stackoverflow explanation comes to help (find the link in references).\n",
    "\n",
    "p0 is the probability (between 0 and 1) that class 0 is chosen.  \n",
    "p1 is the probability (between 0 and 1) that class 1 is chosen.\n",
    "\n",
    "In our problem 1 is Fraudulent, 0 - Not Fraudulent. Then we need the column **p1**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_pandas = h2o.as_list(final_gbm_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds_pandas['p1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(523466,)\n",
      "(523466,)\n"
     ]
    }
   ],
   "source": [
    "print(sub_ids.shape)\n",
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='sub_transactions.csv' target='_blank'>sub_transactions.csv</a><br>"
      ],
      "text/plain": [
       "/Users/araks/Documents/AS_projects/Competitions/hackerearth/BrainWaves2017_18/sub_transactions.csv"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "sub = pd.DataFrame({'transaction_id': sub_ids, 'target': preds})\n",
    "sub = sub[['transaction_id','target']]    \n",
    "\n",
    "filename='sub_transactions.csv'\n",
    "sub.to_csv(filename, index=False)\n",
    "FileLink(filename)      # lb 0.73204"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
